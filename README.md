[![Open in Visual Studio Code](https://classroom.github.com/assets/open-in-vscode-718a45dd9cf7e7f842a935f5ebbe5719a5e09af4491e668f4dbf3b35d5cca122.svg)](https://classroom.github.com/online_ide?assignment_repo_id=11110446&assignment_repo_type=AssignmentRepo)

# Neural Networks and Deep Learning Project: Image Captioning
Welcome to our Image Captioning project! This project utilizes a combination of Convolutional Neural Networks (CNN) and Recurrent Neural Networks (RNN) to generate descriptive captions for images. We have used the ResNet18 model for image feature extraction and an LSTM model for generating captions.

## Project Summary
Image captioning is a challenging task that combines computer vision and natural language processing. The goal of our project is to develop a model that can automatically generate meaningful captions for images. The model takes an image as input and produces a relevant and coherent caption describing the contents of the image.

Our project focuses on implementing a CNN-RNN architecture for image captioning. The CNN (ResNet18) is responsible for extracting visual features from the input image, while the RNN (LSTM) generates the corresponding caption based on the extracted features.

## Code structure
Our code follows a structured organization to ensure clarity and maintainability. The project structure is as follows:

- `data/`: This directory contains the datasets??
- `models/`: This directory contains the weights of the models
- `Fina Notebook.ipynb`: This notebook contains the steps followed in this project.

## Example Code

## Contributors
- Put your name here
- Put your name here
- Júlia Garcia Torné (1630382@uab.cat)

Xarxes Neuronals i Aprenentatge Profund,
Grau de Artificial Intelligence, 
UAB, 2023


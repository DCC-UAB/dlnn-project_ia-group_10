{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the first sweep, we thing that the models using the \"invented\" loss might have some results.\n",
    "Let's visualize them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import LSTMModel , LSTMModel_seeOnce\n",
    "from dataset import ImageCaptionDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/josepsmachine/miniforge3/envs/ML/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from torch.utils.data import DataLoader\n",
    "import wandb\n",
    "import yaml\n",
    "from typing import Dict\n",
    "import gensim.downloader as api\n",
    "import tensorflow_hub as hub\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from tqdm import tqdm\n",
    "from icecream import ic\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "device = \"mps\" #r u running cuda my boy? or mps? :D\n",
    "\n",
    "#load datasets\n",
    "with open('/Users/josepsmachine/Documents/UNI/DL/dlnn-project_ia-group_10/dataset/train_dataset.pkl', 'rb') as inp:\n",
    "    train_dataset = pickle.load(inp)\n",
    "with open('/Users/josepsmachine/Documents/UNI/DL/dlnn-project_ia-group_10/dataset/val_dataset.pkl', 'rb') as inp:\n",
    "    val_dataset = pickle.load(inp)\n",
    "#with open('/Users/josepsmachine/Documents/UNI/DL/dlnn-project_ia-group_10/dataset/debug_dataset.pkl', 'rb') as inp:\n",
    "#    debug_dataset = pickle.load(inp)\n",
    "\n",
    "#create dataloaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "#debug_dataloader = DataLoader(debug_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "#load hyperparamaters to do grid search on\n",
    "#setup wandb stuff\n",
    "with open('hyperparams.yaml', 'r') as stream:\n",
    "    try:\n",
    "        sweep_config = yaml.safe_load(stream)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)\n",
    "\n",
    "\n",
    "#load word2vec pretrained embedding layer\n",
    "word2vec_emb = api.load('word2vec-google-news-300')\n",
    "word2vec_emb = torch.FloatTensor(word2vec_emb.vectors)\n",
    "\n",
    "#import vocabulary to word2vec indexes that we know\n",
    "with open('vocabidx2word2vecidx.pkl', 'rb') as inp:\n",
    "    vocabidx2word2vecidx = pickle.load(inp)\n",
    "\n",
    "with open('vocabulary.pkl', 'rb') as inp:\n",
    "    vocabulary = pickle.load(inp)\n",
    "\n",
    "word2vec_emb = word2vec_emb[vocabidx2word2vecidx]\n",
    "\n",
    "word2vec_emb = nn.Embedding.from_pretrained(word2vec_emb)\n",
    "word2vec_emb.requires_grad_ = False #freeze word2vec embeddding layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_layer = nn.Embedding(num_embeddings=word2vec_emb.weight.shape[0], embedding_dim=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMModel(input_dim=512,embedding_layer=emb_layer,hidden_dim=300,n_layers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load state from vm trained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"LSTM_residuals_v7sk01wn.pt\",map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMModel(\n",
       "  (imf2lstm_h): Linear(in_features=512, out_features=300, bias=True)\n",
       "  (imf2lstm_c): Linear(in_features=512, out_features=300, bias=True)\n",
       "  (embedding): Embedding(8426, 300)\n",
       "  (lstm): LSTM(300, 300, batch_first=True)\n",
       "  (LM_FC): Linear(in_features=300, out_features=8426, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get a sample from the validation dataloader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1,X2,caption = next(iter(val_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('bos man and woman kissing eos',)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 35])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 300])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embedding(torch.tensor([[1]])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'_IncompatibleKeys' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m out, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mX2\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: '_IncompatibleKeys' object is not callable"
     ]
    }
   ],
   "source": [
    "out, _, _ = model(X1,X2,train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 40, 8426])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('bos man and woman kissing eos',)\n",
      " haircut hell packed opposition filming too six tightropes riverboat tether passageway contestant cycler along stunning jeep holding panda reflection ballerina firefighters circuit oncoming distribute narrow oddly dirtbikers laundry chew vegetables overflowing refrigerator upfront grapple annoyed swimsuites noticable chewing discovers when\n"
     ]
    }
   ],
   "source": [
    "sntc = \"\"\n",
    "for tok in out[0]:\n",
    "    #sample one token for each distrib\n",
    "    step = torch.multinomial(tok, 1)\n",
    "    sntc += \" \" + vocabulary[step]\n",
    "\n",
    "print(caption)\n",
    "print(sntc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('ML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "da600ade1a771c82ddf6d22a5a41f856afbf3528a3611e1c80e3ac6da17c9450"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
